{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vsv7LYcbmxAf"
      },
      "outputs": [],
      "source": [
        "#necessary imports\n",
        "from termcolor import colored\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout \n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import ZeroPadding2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Compare the two inputs\n",
        "def comparator(learner, instructor):\n",
        "    if len(learner) != len(instructor):\n",
        "        raise AssertionError(f'Models does not have the same number of layers {len(learner)} != {len(instructor)}')\n",
        "    for a, b in zip(learner, instructor):\n",
        "        if tuple(a) != tuple(b):\n",
        "            print(colored(\"Test failed\", attrs=['bold']),\n",
        "                  \"\\n Expected value \\n\\n\", colored(f\"{b}\", \"green\"), \n",
        "                  \"\\n\\n does not match the input value: \\n\\n\", \n",
        "                  colored(f\"{a}\", \"red\"))\n",
        "            raise AssertionError(\"Error in test\") \n",
        "    print('\\033[92mAll tests passed!')\n",
        "\n",
        "# extracts the description of a given model\n",
        "def summary(model):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    result = []\n",
        "    for layer in model.layers:\n",
        "        descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]\n",
        "        if (type(layer) == Conv2D):\n",
        "            descriptors.append(layer.padding)\n",
        "            descriptors.append(layer.activation.__name__)\n",
        "            descriptors.append(layer.kernel_initializer.__class__.__name__)\n",
        "        if (type(layer) == MaxPooling2D):\n",
        "            descriptors.append(layer.pool_size)\n",
        "            descriptors.append(layer.strides)\n",
        "            descriptors.append(layer.padding)\n",
        "        if (type(layer) == Dropout):\n",
        "            descriptors.append(layer.rate)\n",
        "        if (type(layer) == ZeroPadding2D):\n",
        "            descriptors.append(layer.padding)\n",
        "        if (type(layer) == Dense):\n",
        "            descriptors.append(layer.activation.__name__)\n",
        "        result.append(descriptors)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qAMZrI0buKyh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import math\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('Sign_Dataset/train_signs.h5', \"r\")\n",
        "    # your train set features\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "    train_set_y_orig = np.array(\n",
        "        train_dataset[\"train_set_y\"][:])  # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('/Sign_Dataset/test_signs.h5', \"r\")\n",
        "    # your test set features\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "    test_set_y_orig = np.array(\n",
        "        test_dataset[\"test_set_y\"][:])  # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:])  # the list of classes\n",
        "\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "\n",
        "def random_mini_batches(X, Y, mini_batch_size=64, seed=0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "\n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "\n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "\n",
        "    m = X.shape[0]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation, :, :, :]\n",
        "    shuffled_Y = Y[permutation, :]\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    # number of mini batches of size mini_batch_size in your partitionning\n",
        "    num_complete_minibatches = math.floor(m / mini_batch_size)\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[k * mini_batch_size: k *\n",
        "                                  mini_batch_size + mini_batch_size, :, :, :]\n",
        "        mini_batch_Y = shuffled_Y[k * mini_batch_size: k *\n",
        "                                  mini_batch_size + mini_batch_size, :]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[num_complete_minibatches *\n",
        "                                  mini_batch_size: m, :, :, :]\n",
        "        mini_batch_Y = shuffled_Y[num_complete_minibatches *\n",
        "                                  mini_batch_size: m, :]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    return mini_batches\n",
        "\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n",
        "\n",
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "\n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve the parameters from the dictionary \"parameters\"\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    # Numpy Equivalents:\n",
        "    # Z1 = np.dot(W1, X) + b1\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    # Z2 = np.dot(W2, a1) + b2\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    # Z3 = np.dot(W3,Z2) + b3\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)\n",
        "\n",
        "    return Z3\n",
        "\n",
        "\n",
        "def predict(X, parameters):\n",
        "\n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "\n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "\n",
        "    x = tf.placeholder(\"float\", [12288, 1])\n",
        "\n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "\n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict={x: X})\n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G31ScO4YuO6J"
      },
      "outputs": [],
      "source": [
        "from termcolor import colored\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "import numpy as np\n",
        "\n",
        "def identity_block_test(target):\n",
        "    np.random.seed(1)\n",
        "    #X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
        "    X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "    X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "    X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "    X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "    A3 = target(X,\n",
        "                f = 2,\n",
        "                filters = [4, 4, 3],\n",
        "                initializer=lambda seed=0:constant(value=1),\n",
        "                training=False)\n",
        "\n",
        "\n",
        "    A3np = A3.numpy()\n",
        "    assert tuple(A3np.shape) == (3, 4, 4, 3), \"Shapes does not match. This is really weird\"\n",
        "    assert np.all(A3np >= 0), \"The ReLu activation at the last layer is missing\"\n",
        "    resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
        "\n",
        "    assert np.floor(resume[1, 0, 0]) == 2 * np.floor(resume[1, 0, 3]), \"Check the padding and strides\"\n",
        "    assert np.floor(resume[1, 0, 3]) == np.floor(resume[1, 1, 0]),     \"Check the padding and strides\"\n",
        "    assert np.floor(resume[1, 1, 0]) == 2 * np.floor(resume[1, 1, 3]), \"Check the padding and strides\"\n",
        "    assert np.floor(resume[1, 1, 0]) == 2 * np.floor(resume[1, 1, 3]), \"Check the padding and strides\"\n",
        "\n",
        "    assert resume[1, 1, 0] - np.floor(resume[1, 1, 0]) > 0.7, \"Looks like the BatchNormalization units are not working\"\n",
        "\n",
        "    assert np.allclose(resume, \n",
        "                       np.array([[[0.0,       0.0,       0.0,        0.0],\n",
        "                                  [0.0,       0.0,       0.0,        0.0]],\n",
        "                                 [[192.71236, 192.71236, 192.71236,  96.85619],\n",
        "                                  [ 96.85619,  96.85619,  96.85619,  48.9281 ]],\n",
        "                                 [[578.1371,   578.1371,  578.1371,  290.56854],\n",
        "                                  [290.56854,  290.56854, 290.56854, 146.78427]]]), atol = 1e-5 ), \"Wrong values with training=False\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    A4 = target(X,\n",
        "                f = 3,\n",
        "                filters = [3, 3, 3],\n",
        "                initializer=lambda seed=7:constant(value=1),\n",
        "                training=True)\n",
        "    A4np = A4.numpy()\n",
        "    resume = A4np[:,(0,-1),:,:].mean(axis = 3)\n",
        "    assert np.allclose(resume, \n",
        "                         np.array([[[0.,         0.,        0.,      0.,        ],\n",
        "                                  [0.,         0.,        0.,        0.,        ]],\n",
        "                                 [[0.37394285, 0.37394285, 0.37394285, 0.37394285],\n",
        "                                  [0.37394285, 0.37394285, 0.37394285, 0.37394285]],\n",
        "                                 [[3.2379014,  4.1394243,  4.1394243,  3.2379014 ],\n",
        "                                  [3.2379014,  4.1394243,  4.1394243,  3.2379014 ]]]), atol = 1e-5 ), \"Wrong values with training=True\"\n",
        "\n",
        "    print('\\033[92mAll tests passed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SryAhykyuWBg"
      },
      "outputs": [],
      "source": [
        "convolutional_block_output1 = [[[[0.,         0.66683817, 0.,         0.,        0.888539,   0.5274254 ],\n",
        "   [0.,         0.65053666, 0.,         0.,         0.8959285,  0.49965227]],\n",
        "  [[0.,         0.6312079,  0.,         0.,         0.86362475, 0.47643146],\n",
        "   [0.,         0.56883204, 0.,        0.,         0.8553412,  0.417093 ]]],\n",
        " [[[1.0951002,  0.,         1.5761349,  0.6267836,  0.,         0.,        ],\n",
        "   [1.3594234,  0.,         1.6074152,  0.6536726,  0.,         0.,        ]],\n",
        "  [[0.49971345, 0.,         0.9446775,  0.6636579,  0.,         0.,        ],\n",
        "   [0.98098886, 0.,         1.0731578,  0.6013661,  0.,         0.,        ]]],\n",
        " [[[3.2853007,  0.,         4.728405,   1.8803508,  0.,         0.,        ],\n",
        "   [4.07827,    0.,         4.8222456,  1.9610177,  0.,         0.,        ]],\n",
        "  [[1.4991404,  0.,         2.8340323,  1.9909737,  0.,         0.,        ],\n",
        "   [2.9429667,  0.,         3.2194734,  1.8040984,  0.,         0.       ]]]]\n",
        "\n",
        "convolutional_block_output2 = [[[[0.       , 2.7823157, 0.       , 0.       , 1.6960442, 2.8218517],\n",
        "   [0.       , 1.5445004, 0.       , 0.       , 2.170656 , 1.3908148]],\n",
        "  [[0.       , 1.9399526, 0.       , 0.       , 1.4798119, 1.9157798],\n",
        "   [0.       , 0.       , 0.       , 0.9879823, 1.1234158, 0.       ]]],\n",
        " [[[0.,         0.4073585,  0.,         0.60906595, 0.61729676, 0.43824518],\n",
        "   [0.,         0.4073585,  0.,         0.60906595, 0.61729676, 0.43824518]],\n",
        "  [[0.,         0.4073585,  0.,         0.60906595, 0.61729676, 0.43824518],\n",
        "   [0.,         0.4073585,  0.,         0.60906595, 0.61729676, 0.43824518]]],\n",
        " [[[2.6159182,  0.,         2.752994,   0.,         0.,         0.,        ],\n",
        "   [3.4472604,  0.,         2.7312024,  0.03319526, 0.,         0.,        ]],\n",
        "  [[0.9830525,  0.,         1.6564476,  0.9591365,  0.,         0.,        ],\n",
        "   [2.5460882,  0.,         1.1291425,  0.,         0.,         0.,        ]]]]\n",
        "\n",
        "\n",
        "ResNet50_summary =[['InputLayer', [(None, 64, 64, 3)], 0],\n",
        "['ZeroPadding2D', (None, 70, 70, 3), 0, ((3, 3), (3, 3))],\n",
        "['Conv2D', (None, 32, 32, 64), 9472, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 32, 32, 64), 256],\n",
        "['Activation', (None, 32, 32, 64), 0],\n",
        "['MaxPooling2D', (None, 15, 15, 64), 0, (3, 3), (2, 2), 'valid'],\n",
        "['Conv2D', (None, 15, 15, 64), 4160, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 64), 256],\n",
        "['Activation', (None, 15, 15, 64), 0],\n",
        "['Conv2D', (None, 15, 15, 64), 36928, 'same', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 64), 256],\n",
        "['Activation', (None, 15, 15, 64), 0],\n",
        "['Conv2D', (None, 15, 15, 256), 16640, 'valid', 'linear', 'GlorotUniform'],\n",
        "['Conv2D', (None, 15, 15, 256), 16640, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 256), 1024],\n",
        "['BatchNormalization', (None, 15, 15, 256), 1024],\n",
        "['Add', (None, 15, 15, 256), 0],\n",
        "['Activation', (None, 15, 15, 256), 0],\n",
        "['Conv2D', (None, 15, 15, 64), 16448, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 64), 256],\n",
        "['Activation', (None, 15, 15, 64), 0],\n",
        "['Conv2D', (None, 15, 15, 64), 36928, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 64), 256],\n",
        "['Activation', (None, 15, 15, 64), 0],\n",
        "['Conv2D', (None, 15, 15, 256), 16640, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 256), 1024],\n",
        "['Add', (None, 15, 15, 256), 0],\n",
        "['Activation', (None, 15, 15, 256), 0],\n",
        "['Conv2D', (None, 15, 15, 64), 16448, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 64), 256],\n",
        "['Activation', (None, 15, 15, 64), 0],\n",
        "['Conv2D', (None, 15, 15, 64), 36928, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 64), 256],\n",
        "['Activation', (None, 15, 15, 64), 0],\n",
        "['Conv2D', (None, 15, 15, 256), 16640, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 15, 15, 256), 1024],\n",
        "['Add', (None, 15, 15, 256), 0],\n",
        "['Activation', (None, 15, 15, 256), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 32896, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 147584, 'same', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 512), 66048, 'valid', 'linear', 'GlorotUniform'],\n",
        "['Conv2D', (None, 8, 8, 512), 131584, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 512), 2048],\n",
        "['BatchNormalization', (None, 8, 8, 512), 2048],\n",
        "['Add', (None, 8, 8, 512), 0],\n",
        "['Activation', (None, 8, 8, 512), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 65664, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 147584, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 512), 66048, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 512), 2048],\n",
        "['Add', (None, 8, 8, 512), 0],\n",
        "['Activation', (None, 8, 8, 512), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 65664, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 147584, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 512), 66048, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 512), 2048],\n",
        "['Add', (None, 8, 8, 512), 0],\n",
        "['Activation', (None, 8, 8, 512), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 65664, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 128), 147584, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 128), 512],\n",
        "['Activation', (None, 8, 8, 128), 0],\n",
        "['Conv2D', (None, 8, 8, 512), 66048, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 8, 8, 512), 2048],\n",
        "['Add', (None, 8, 8, 512), 0],\n",
        "['Activation', (None, 8, 8, 512), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 131328, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 590080, 'same', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 1024), 263168, 'valid', 'linear', 'GlorotUniform'],\n",
        "['Conv2D', (None, 4, 4, 1024), 525312, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 1024), 4096],\n",
        "['BatchNormalization', (None, 4, 4, 1024), 4096],\n",
        "['Add', (None, 4, 4, 1024), 0],\n",
        "['Activation', (None, 4, 4, 1024), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 262400, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 590080, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 1024), 263168, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 1024), 4096],\n",
        "['Add', (None, 4, 4, 1024), 0],\n",
        "['Activation', (None, 4, 4, 1024), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 262400, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 590080, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 1024), 263168, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 1024), 4096],\n",
        "['Add', (None, 4, 4, 1024), 0],\n",
        "['Activation', (None, 4, 4, 1024), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 262400, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 590080, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 1024), 263168, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 1024), 4096],\n",
        "['Add', (None, 4, 4, 1024), 0],\n",
        "['Activation', (None, 4, 4, 1024), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 262400, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 590080, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 1024), 263168, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 1024), 4096],\n",
        "['Add', (None, 4, 4, 1024), 0],\n",
        "['Activation', (None, 4, 4, 1024), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 262400, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 256), 590080, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 256), 1024],\n",
        "['Activation', (None, 4, 4, 256), 0],\n",
        "['Conv2D', (None, 4, 4, 1024), 263168, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 4, 4, 1024), 4096],\n",
        "['Add', (None, 4, 4, 1024), 0],\n",
        "['Activation', (None, 4, 4, 1024), 0],\n",
        "['Conv2D', (None, 2, 2, 512), 524800, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 512), 2048],\n",
        "['Activation', (None, 2, 2, 512), 0],\n",
        "['Conv2D', (None, 2, 2, 512), 2359808, 'same', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 512), 2048],\n",
        "['Activation', (None, 2, 2, 512), 0],\n",
        "['Conv2D', (None, 2, 2, 2048), 1050624, 'valid', 'linear', 'GlorotUniform'],\n",
        "['Conv2D', (None, 2, 2, 2048), 2099200, 'valid', 'linear', 'GlorotUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 2048), 8192],\n",
        "['BatchNormalization', (None, 2, 2, 2048), 8192],\n",
        "['Add', (None, 2, 2, 2048), 0],\n",
        "['Activation', (None, 2, 2, 2048), 0],\n",
        "['Conv2D', (None, 2, 2, 512), 1049088, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 512), 2048],\n",
        "['Activation', (None, 2, 2, 512), 0],\n",
        "['Conv2D', (None, 2, 2, 512), 2359808, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 512), 2048],\n",
        "['Activation', (None, 2, 2, 512), 0],\n",
        "['Conv2D', (None, 2, 2, 2048), 1050624, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 2048), 8192],\n",
        "['Add', (None, 2, 2, 2048), 0],\n",
        "['Activation', (None, 2, 2, 2048), 0],\n",
        "['Conv2D', (None, 2, 2, 512), 1049088, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 512), 2048],\n",
        "['Activation', (None, 2, 2, 512), 0],\n",
        "['Conv2D', (None, 2, 2, 512), 2359808, 'same', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 512), 2048],\n",
        "['Activation', (None, 2, 2, 512), 0],\n",
        "['Conv2D', (None, 2, 2, 2048), 1050624, 'valid', 'linear', 'RandomUniform'],\n",
        "['BatchNormalization', (None, 2, 2, 2048), 8192],\n",
        "['Add', (None, 2, 2, 2048), 0],\n",
        "['Activation', (None, 2, 2, 2048), 0],\n",
        "['AveragePooling2D', (None, 1, 1, 2048), 0],\n",
        "['Flatten', (None, 2048), 0],\n",
        "['Dense', (None, 6), 12294, 'softmax']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hxlNuSw5tgvN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1eE0c_l8mpb4"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: identity_block\n",
        "\n",
        "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    cache = []\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    \n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation('relu')(X)\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoKObBQuoiiJ",
        "outputId": "934b2aee-1697-462d-cc0d-44e9b4d4c4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mWith training=False\u001b[0m\n",
            "\n",
            "[[[  0.        0.        0.        0.     ]\n",
            "  [  0.        0.        0.        0.     ]]\n",
            "\n",
            " [[192.71236 192.71236 192.71236  96.85619]\n",
            "  [ 96.85619  96.85619  96.85619  48.9281 ]]\n",
            "\n",
            " [[578.1371  578.1371  578.1371  290.56854]\n",
            "  [290.56854 290.56854 290.56854 146.78427]]]\n",
            "96.85619\n",
            "\n",
            "\u001b[1mWith training=True\u001b[0m\n",
            "\n",
            "[[[0.      0.      0.      0.     ]\n",
            "  [0.      0.      0.      0.     ]]\n",
            "\n",
            " [[0.40739 0.40739 0.40739 0.40739]\n",
            "  [0.40739 0.40739 0.40739 0.40739]]\n",
            "\n",
            " [[4.99991 4.99991 4.99991 3.25948]\n",
            "  [3.25948 3.25948 3.25948 2.40739]]]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A3 = identity_block(X, f=2, filters=[4, 4, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=False)\n",
        "print('\\033[1mWith training=False\\033[0m\\n')\n",
        "A3np = A3.numpy()\n",
        "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
        "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
        "print(resume[1, 1, 0])\n",
        "\n",
        "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
        "np.random.seed(1)\n",
        "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
        "                   initializer=lambda seed=0:constant(value=1),\n",
        "                   training=True)\n",
        "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
        "\n",
        "identity_block_test(identity_block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OyoALJdtolum"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: convolutional_block\n",
        "\n",
        "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
        "                   also called Xavier uniform initializer.\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    \n",
        "    # First component of main path glorot_uniform(seed=0)\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    ## Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = f,strides = (1, 1),padding='same',kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training=training)\n",
        "    \n",
        "    ##### SHORTCUT PATH ##### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training=training)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JArBtGJu2Fo",
        "outputId": "20f0d6c3-cc7c-4438-f96f-95ee117106c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[0.         0.66683817 0.         0.         0.888539   0.5274254 ]\n",
            "  [0.         0.65053666 0.         0.         0.8959285  0.49965227]]\n",
            "\n",
            " [[0.         0.6312079  0.         0.         0.86362475 0.47643146]\n",
            "  [0.         0.56883204 0.         0.         0.8553412  0.417093  ]]], shape=(2, 2, 6), dtype=float32)\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
        "X1 = np.ones((1, 4, 4, 3)) * -1\n",
        "X2 = np.ones((1, 4, 4, 3)) * 1\n",
        "X3 = np.ones((1, 4, 4, 3)) * 3\n",
        "\n",
        "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
        "\n",
        "A = convolutional_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
        "\n",
        "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
        "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
        "assert np.allclose(A.numpy(), convolutional_block_output1), \"Wrong values when training=False.\"\n",
        "print(A[0])\n",
        "\n",
        "B = convolutional_block(X, f = 2, filters = [2, 4, 6], training=True)\n",
        "assert np.allclose(B.numpy(), convolutional_block_output2), \"Wrong values when training=True.\"\n",
        "\n",
        "print('\\033[92mAll tests passed!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9_sJmQ6FvAQ9"
      },
      "outputs": [],
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: ResNet50\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    ## Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128,128,512], s = 2)\n",
        "    X = identity_block(X, 3,  [128,128,512])\n",
        "    X = identity_block(X, 3,  [128,128,512])\n",
        "    X = identity_block(X, 3,  [128,128,512])\n",
        "    \n",
        "    ## Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "\n",
        "    ## Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "\n",
        "    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2, 2))(X)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5YfOUenvhu3",
        "outputId": "9ddee166-334e-4c42-f4a8-5a99d027537b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)   0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 32, 32, 64)   9472        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32, 32, 64)  256         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 15, 15, 64)   0           ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 15, 15, 64)   4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 15, 15, 64)  256         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 15, 15, 64)  256         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 15, 15, 256)  16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 15, 15, 256)  0           ['batch_normalization_23[0][0]', \n",
            "                                                                  'batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 15, 15, 256)  0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 15, 15, 64)  256         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 15, 15, 64)  256         ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 15, 15, 256)  0           ['activation_21[0][0]',          \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 15, 15, 256)  0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 15, 15, 64)   16448       ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 15, 15, 64)  256         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 15, 15, 64)   36928       ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 15, 15, 64)  256         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 15, 15, 256)  16640       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 15, 15, 256)  0           ['activation_24[0][0]',          \n",
            "                                                                  'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 15, 15, 256)  0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 8, 8, 128)    32896       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 8, 8, 128)   512         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 8, 8, 128)   512         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 8, 8, 512)    131584      ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 8, 8, 512)    0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 8, 8, 512)    0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 8, 8, 128)   512         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 8, 8, 128)   512         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 8, 8, 512)    0           ['activation_30[0][0]',          \n",
            "                                                                  'batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 8, 8, 512)    0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 8, 8, 128)   512         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 8, 8, 128)   512         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 8, 8, 512)    0           ['activation_33[0][0]',          \n",
            "                                                                  'batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 8, 8, 512)    0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 8, 8, 128)    65664       ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 8, 8, 128)   512         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 8, 8, 128)    147584      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 8, 8, 128)   512         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 8, 8, 128)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 8, 8, 512)    66048       ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 8, 8, 512)   2048        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 8, 8, 512)    0           ['activation_36[0][0]',          \n",
            "                                                                  'batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 8, 8, 512)    0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 4, 4, 256)    131328      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 4, 4, 1024)   525312      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 4, 4, 1024)   0           ['batch_normalization_46[0][0]', \n",
            "                                                                  'batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 4, 4, 1024)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 4, 4, 1024)   0           ['activation_42[0][0]',          \n",
            "                                                                  'batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 4, 4, 1024)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 4, 4, 1024)   0           ['activation_45[0][0]',          \n",
            "                                                                  'batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 4, 4, 1024)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_48[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_50[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 4, 4, 1024)   0           ['activation_48[0][0]',          \n",
            "                                                                  'batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 4, 4, 1024)   0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 4, 4, 1024)   0           ['activation_51[0][0]',          \n",
            "                                                                  'batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 4, 4, 1024)   0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 4, 4, 256)    262400      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 4, 4, 256)    590080      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 4, 4, 256)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 4, 4, 1024)   263168      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 4, 4, 1024)  4096        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 4, 4, 1024)   0           ['activation_54[0][0]',          \n",
            "                                                                  'batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 4, 4, 1024)   0           ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 2, 2, 512)    524800      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_58[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 2, 2, 2048)   2099200     ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 2, 2, 2048)   0           ['batch_normalization_65[0][0]', \n",
            "                                                                  'batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 2, 2, 2048)   0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_60[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 2, 2, 2048)   0           ['activation_60[0][0]',          \n",
            "                                                                  'batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 2, 2, 2048)   0           ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 2, 2, 512)    1049088     ['activation_63[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 2, 2, 512)    2359808     ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 2, 2, 512)   2048        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 2, 2, 512)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 2, 2, 2048)   1050624     ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 2, 2, 2048)  8192        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 2, 2, 2048)   0           ['activation_63[0][0]',          \n",
            "                                                                  'batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 2, 2, 2048)   0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_66[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 6)            12294       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,600,006\n",
            "Trainable params: 23,546,886\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndfitMiGvj3-",
        "outputId": "9bf334ff-3d98-4ec6-88c2-586ea874da85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
        "\n",
        "comparator(summary(model), ResNet50_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EWQwVZB2vq3W"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b9gNyWHwggf",
        "outputId": "95035a95-b8eb-4397-a572-34f939dd90d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (1080, 64, 64, 3)\n",
            "Y_train shape: (1080, 6)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "Y_test shape: (120, 6)\n"
          ]
        }
      ],
      "source": [
        "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "# Normalize image vectors\n",
        "X_train = X_train_orig / 255.\n",
        "X_test = X_test_orig / 255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-isOtJWqwtP1",
        "outputId": "0f7b1d21-215a-43ca-8d0e-ac6fc195774f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 211s 6s/step - loss: 2.1995 - accuracy: 0.4778\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 188s 6s/step - loss: 0.6381 - accuracy: 0.7769\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 194s 6s/step - loss: 0.5199 - accuracy: 0.8389\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 191s 6s/step - loss: 0.8184 - accuracy: 0.7074\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 194s 6s/step - loss: 0.3569 - accuracy: 0.8704\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 191s 6s/step - loss: 0.2200 - accuracy: 0.9259\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 191s 6s/step - loss: 0.3882 - accuracy: 0.8991\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 191s 6s/step - loss: 0.4464 - accuracy: 0.8722\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 191s 6s/step - loss: 0.1882 - accuracy: 0.9352\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 191s 6s/step - loss: 0.0702 - accuracy: 0.9741\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff46dc1c2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs = 10, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bybW52bRwwSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7227689-9ab9-4ec3-c893-f0d67840f30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 3s 465ms/step - loss: 0.2114 - accuracy: 0.9417\n",
            "Loss = 0.2113729566335678\n",
            "Test Accuracy = 0.9416666626930237\n"
          ]
        }
      ],
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15NPNrK75lJ-PRF2ofRJxLCDeHPa2-Xz7",
      "authorship_tag": "ABX9TyOPJEhdtA9aEUrpwceUHIGS"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}